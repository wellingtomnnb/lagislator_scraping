{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url: str):\n",
    "    \"\"\" ### get_soup\n",
    "    Faz uma requisição GET para a URL passada como parâmetro e\n",
    "    retorna um objeto do tipo BeautifulSoup\n",
    "    \"\"\"\n",
    "\n",
    "    html_content = requests.get(url).text\n",
    "    soup = bs4.BeautifulSoup(html_content, 'lxml')\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_soap_data(soap_data, proposicao:int, ano:int):\n",
    "    \"\"\" ### load_soap_data\n",
    "    Interpreta os dados oriundos de uma página HTML\n",
    "    parâmetros:\n",
    "    * soap_data: objeto do tipo BeautifulSoup com os dados do HTML\n",
    "    * proposicao: número da proposição\n",
    "    * ano: ano da proposição (data inicial: 1997)\n",
    "    \"\"\"\n",
    "\n",
    "    # obtém a lista de chave e valores oriundos do body da pagina\n",
    "    keys = soap_data.find_all('dt')\n",
    "    values = soap_data.find_all('dd')\n",
    "    values = soap_data.find_all('dd')\n",
    "\n",
    "    # cria um dict baseando-se na zipagem das listas\n",
    "    dados = {\n",
    "      key.get_text().lower(): value.get_text()\n",
    "      for key, value in zip(keys, values)\n",
    "    }\n",
    "\n",
    "    # obtem o texto do paragrafo\n",
    "    texto = soap_data.find('p').get_text()\n",
    "\n",
    "    # cria um novos keys para armazenar os dados extras\n",
    "    dados['texto'] = texto\n",
    "    dados['proposicao'] = proposicao\n",
    "    dados['ano'] = ano\n",
    "\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"### get_data\n",
    "    Obtém dados a partir do web scraping da pagina *legislador*\n",
    "    \"\"\"\n",
    "\n",
    "    # define mecanismos de manipulação da URL\n",
    "    url_base = \"https://www.legislador.com.br//LegisladorWEB.ASP?WCI=ProposicaoTexto&ID=3&TPProposicao=1&nr\"\n",
    "    url_dynamic =  lambda prop, ano: f'{url_base}Proposicao={prop}&aaProposicao={ano}'\n",
    "\n",
    "    # define dadas de inicio e fim da execução\n",
    "    end_year = datetime.datetime.now().year + 1\n",
    "    start_year = 2022\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for ano in range(start_year, end_year):\n",
    "        proposicao = 1\n",
    "        raw_data = get_soup( url_dynamic(proposicao, ano) )\n",
    "        has_data = len(raw_data.findAll('dt')) > 0\n",
    "\n",
    "        while has_data:\n",
    "\n",
    "            # para o processo apenas para agilizar os testes\n",
    "            if proposicao >= 11: break\n",
    "\n",
    "            result.append(load_soap_data(raw_data, proposicao, ano))\n",
    "\n",
    "            proposicao += 1\n",
    "            raw_data = get_soup( url_dynamic(proposicao, ano) )\n",
    "            has_data = len(raw_data.findAll('dt')) > 0\n",
    "\n",
    "            print('proposicao:', f'{ano}-{proposicao}', end='\\r')\n",
    "\n",
    "        print(f'Total de Preposições em {ano}:', proposicao)\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Preposições em 2022: 11\n",
      "Total de Preposições em 2023: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preposicoes = get_data()\n",
    "len(preposicoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reunião': '03/02/2022',\n",
       " 'deliberação': '03/02/2022',\n",
       " 'situação': 'Proposição Despachada',\n",
       " 'assunto': 'Limpeza, Macadamização, Patrolamento, Retificação; Alargamento',\n",
       " 'autor': 'Vereador Anderson Luz dos Santos.',\n",
       " 'texto': 'O vereador que esta subscreve, no uso das atribuições que lhe confere o Regimento Interno desta Casa Legislativa, vem requerer, após ouvido o colendo Plenário, encaminhamento de cópia da presente Indicação à Secretaria de Obras sugerindo o exposto a seguir: Manutenção da pista (fechar buraco) na rua Izabel Wolff, bairro Estrada das Areias (imagem anexa).',\n",
       " 'proposicao': 1,\n",
       " 'ano': 2022}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preposicoes[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
